{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_facenet\n",
    "from keras_facenet import FaceNet\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import os\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import time\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "from gtts import gTTS\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Face recognition\n",
    "class face_recogntion():\n",
    "    def __init__(self):\n",
    "        #create the facenet detector, using default weights\n",
    "        self.embedder = FaceNet('20170511-185253')\n",
    "        self.detector = MTCNN()\n",
    "        ##saving path to store the known faces \n",
    "        self.face_embedding_path = 'face_embeddings/knownFaces.pickle'\n",
    "        self.previous_time = None\n",
    "        \n",
    "    def face_detect(self,image,model_size,show=True):\n",
    "        result = self.detector.detect_faces(image)\n",
    "        faces = []\n",
    "        face_coord = []\n",
    "        I = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "        for i in range(len(result)):\n",
    "            [x,y,w,h] = result[i]['box'] #top left top rigth and width and height\n",
    "            #ctrx = round(x+0.5*w)\n",
    "            #ctry = round(y+0.5*h)\n",
    "            x1 = int(x)\n",
    "            y1 = int(y)\n",
    "            x2 = int(x)+int(w)\n",
    "            y2 = int(y)+int(h)\n",
    "                \n",
    "            face = image[y1:y2,x1:x2,:]\n",
    "            try:\n",
    "                if (x2-x1)*(y2-y1)>20:\n",
    "                    cv2.rectangle(I,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    face = cv2.resize(face,(160,160))\n",
    "                    faces.append(np.expand_dims(np.array(face),axis=0))\n",
    "                    face_coord.append((x1,y1,x2,y2))\n",
    "                #print(\"found_faces\")\n",
    "            except Exception as e:\n",
    "                pass\n",
    "        #cv2.imshow('faces',I)\n",
    "        #cv2.waitKey(5)\n",
    "        #cv2.destroyAllWindows()\n",
    "        return faces,face_coord,I\n",
    "    def face_emb(self,faces):\n",
    "        embeddings = []\n",
    "        for face in faces:\n",
    "            # scale pixel values\n",
    "            emb = self.embedder.embeddings(face)\n",
    "            embeddings.append(emb)\n",
    "        return embeddings\n",
    "    def dist_in_faces(self,new_face,old_face):\n",
    "        #embeddings_diff = old_face-new_face\n",
    "        dist = distance.euclidean(old_face,new_face)\n",
    "        return dist\n",
    "    def face_identification(self,image,show = True,T=1):\n",
    "        #camera view state the image whether right or left\n",
    "        #T = threshold for the distance betweent the pixel\n",
    "        model_size = (160,160)\n",
    "        faces,face_coord,fimage = self.face_detect(image,model_size,show)\n",
    "        faces = faces\n",
    "        #face_coord = face_coord\n",
    "        embeddings = self.face_emb(faces)\n",
    "        face_data= dict()\n",
    "        with open(self.face_embedding_path,'rb') as file:\n",
    "            face_data = pickle.load(file)\n",
    "            #contain the key=name value=embedding\n",
    "        #print(face_data)\n",
    "        identified_faces = dict()\n",
    "        #print(face_data)\n",
    "        for i in range(len(embeddings)):\n",
    "            for key,value in face_data.items():\n",
    "                dist = self.dist_in_faces(embeddings[i],value)\n",
    "                if dist<T:\n",
    "                    identified_faces[(face_coord[i])] = key\n",
    "                else:\n",
    "                    identified_faces[(face_coord[i])] = 'unknown'\n",
    "                    \n",
    "                    #print(key+\" \"+str(face_coord[i]))\n",
    "        \n",
    "        return identified_faces,fimage\n",
    "    \n",
    "    def display_face(self,identyface,camera_view,image,speech='pyttsx'):\n",
    "        \n",
    "        I = image.copy()\n",
    "        #image is the output of the face_identification\n",
    "        #identyface is the output of face_identification function\n",
    "        shape = I.shape\n",
    "        c = round(shape[1]/2)#centre of the image through column\n",
    "        Text = [] #the words to say\n",
    "        names = []\n",
    "        for coord,name in identyface.items():\n",
    "            (x1,y1,x2,y2) = coord #top left top rigth and width and height\n",
    "            ctr_x = x1+round(0.5*(x2-x1))\n",
    "            if camera_view=='left' and ctr_x<=c:\n",
    "                Text.append(name +  ' is in left of you')\n",
    "            elif camera_view=='right' and ctr_x>=c:\n",
    "                Text.append(name +  ' is in right of you')\n",
    "            else:\n",
    "                Text.append(name +  ' is in centre of you')\n",
    "            text = name\n",
    "            names.append(name)\n",
    "            cv2.putText(I, text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, (255,0,0), 2)\n",
    "            #cv2.rectangle(I,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "        string = ' and '.join(Text)\n",
    "    \n",
    "        if self.previous_time == None:\n",
    "            self.previous_time = time.time()\n",
    "        new_time = time.time()\n",
    "        if 10<=new_time-self.previous_time<=20:\n",
    "            if speech=='pyttsx' and len(Text)>0:\n",
    "                print(string)\n",
    "                engine.say(string)\n",
    "                engine.runAndWait()\n",
    "            elif speech=='gtts' and len(Text)>0:\n",
    "                print(string)\n",
    "                if camera_view = 'right':\n",
    "                    filename = 'temp_right.mp3'\n",
    "                else:\n",
    "                    filename = 'temp_left.mp3'\n",
    "                tts = gTTS(text=string, lang='en-in')\n",
    "                tts.save(filename)\n",
    "                playsound(filename)\n",
    "        #sleep(music.duration) #prevent from killing\n",
    "                os.remove(filename) #remove temperory file\n",
    "            else : \n",
    "                print('no sound for faces')\n",
    "            self.previous_time = new_time\n",
    "        else:\n",
    "            pass\n",
    "        return I,names\n",
    "    def safe_face(self,face,name):\n",
    "        #face_embeddings data with name\n",
    "        f_data = dict()\n",
    "        #face,coord,_ = self.face_detect(face_image,model_size=(160,160))\n",
    "        #f_image = cv2.resize(face_image,(160,160))\n",
    "        #face_pixels = np.expand_dims(np.array(f_image).astype('float32'),axis=0)\n",
    "        face_embedding = self.embedder.embeddings(face[0])\n",
    "        with open(self.face_embedding_path, 'rb') as file:\n",
    "            f_data = pickle.load(file)\n",
    "        if name not in f_data.keys():\n",
    "            with open(self.face_embedding_path, 'ab') as file:\n",
    "                f_data[name] = face_embedding\n",
    "                pickle.dump(f_data,file)\n",
    "                print('saving completed !!')\n",
    "        else:\n",
    "            print(\"already exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Object detection\n",
    "class object_detection():\n",
    "    #def __init__(self,path):\n",
    "    #    self.path = path\n",
    "    def __init__(self):\n",
    "        self.previous_time = None\n",
    "        labelsPath = \"model/yolov3/coco.names\"\n",
    "        self.LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    " \n",
    "        # initialize a list of colors to represent each possible class label\n",
    "        np.random.seed(42)\n",
    "        self.COLORS = np.random.randint(0, 255, size=(len(self.LABELS), 3),\n",
    "            dtype=\"uint8\")\n",
    "        weightsPath = \"model/yolov3/yolov3.weights\"\n",
    "        configPath = \"model/yolov3/yolov3.cfg\"\n",
    "\n",
    "        # load our YOLO object detector trained on COCO dataset (80 classes)\n",
    "        print(\"[INFO] loading YOLO from disk...\")\n",
    "        self.net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "\n",
    "    def object_detect(self,path,video=False):\n",
    "        if video:\n",
    "            image = path\n",
    "        else:\n",
    "            image = cv2.imread(path)\n",
    "        grey_image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "        (H, W) = image.shape[:2]\n",
    "        net = self.net\n",
    "        # determine only the *output* layer names that we need from YOLO\n",
    "        ln = net.getLayerNames()\n",
    "        ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "        # construct a blob from the input image and then perform a forward\n",
    "        # pass of the YOLO object detector, giving us our bounding boxes and\n",
    "        # associated probabilities\n",
    "        blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "            swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        start = time.time()\n",
    "        layerOutputs = net.forward(ln)\n",
    "        end = time.time()\n",
    "\n",
    "        # show timing information on YOLO\n",
    "        #print(\"[INFO] YOLO took {:.6f} seconds\".format(end - start))\n",
    "        # initialize our lists of detected bounding boxes, confidences, and\n",
    "        C = 0.5 #confidence\n",
    "        T = 0.3 #threshold\n",
    "        # class IDs, respectively\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []\n",
    "        # loop over each of the layer outputs\n",
    "        for output in layerOutputs:\n",
    "            # loop over each of the detections\n",
    "            for detection in output:\n",
    "                # extract the class ID and confidence (i.e., probability) of\n",
    "                # the current object detection\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "\n",
    "                # filter out weak predictions by ensuring the detected\n",
    "                # probability is greater than the minimum probability\n",
    "                if confidence > C:\n",
    "                    # scale the bounding box coordinates back relative to the\n",
    "                    # size of the image, keeping in mind that YOLO actually\n",
    "                    # returns the center (x, y)-coordinates of the bounding\n",
    "                    # box followed by the boxes' width and height\n",
    "                    box = detection[0:4] * np.array([W, H, W, H])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                    # use the center (x, y)-coordinates to derive the top and\n",
    "                    # and left corner of the bounding box\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "\n",
    "                    # update our list of bounding box coordinates, confidences,\n",
    "                    # and class IDs\n",
    "                    boxes.append([x, y, int(width), int(height)])\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, confidences, C,T)\n",
    "        return idxs,classIDs,confidences,boxes,image\n",
    "    \n",
    "    def normalize(self,image):\n",
    "        imag = np.array(image).astype(float)\n",
    "        norm_image = (imag-np.min(imag))*(1/(np.max(imag)-np.min(imag)))\n",
    "        return norm_image\n",
    "    \n",
    "    def take_object(self,path,camera_view,video=False,speech = 'pyttsx') :\n",
    "        #take the grid for distance computations\n",
    "        idxs,classIDs,confidences,boxes,image = self.object_detect(path,video)\n",
    "        #LABELS\n",
    "        LABELS = self.LABELS\n",
    "        #count the objects through label_dict\n",
    "        label_dict = dict()\n",
    "        #take the grid for calculation of the distance from the object\n",
    "        GRID = dict()\n",
    "        # ensure at least one detection exists\n",
    "        Image = image.copy()\n",
    "        shape = Image.shape\n",
    "        c = round(shape[1]/2)\n",
    "        gray_image = cv2.cvtColor(Image,cv2.COLOR_BGR2GRAY)\n",
    "        norm_image = self.normalize(gray_image)\n",
    "        Text = [] #this the list of string the sound will play\n",
    "        if len(idxs)>0:\n",
    "            for i in idxs.flatten():\n",
    "                (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                ctx = round(x+0.5*w)\n",
    "                cty = round(y+0.5*h)\n",
    "                grid = np.array(norm_image[cty-2:cty+2,ctx-2:ctx+2]) #10*10 grid for stereo computation of sum of square differences\n",
    "                name = LABELS[classIDs[i]]\n",
    "                GRID[(name,ctx,cty,camera_view)] = grid\n",
    "                #grid = np.array(image[y:y+h,x:x+w])\n",
    "                label_dict[name] = label_dict.get(name,0)+1\n",
    "                # draw a bounding box rectangle and label on the image\n",
    "                color = [int(c) for c in self.COLORS[classIDs[i]]]\n",
    "                cv2.rectangle(Image, (x, y), (x + w, y + h), color, 2)\n",
    "                text = \"{}: {}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "                cv2.putText(Image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 2)\n",
    "                if camera_view=='left' and ctx<=c:\n",
    "                    Text.append(name + ' ' + str(label_dict[name]) + ' is in left ')\n",
    "                elif camera_view=='right' and ctx>=c:\n",
    "                    Text.append(name + ' ' + str(label_dict[name]) + ' is in right ')\n",
    "                else:\n",
    "                    Text.append(name + ' ' + str(label_dict[name]) + ' is in centre ')\n",
    "                \n",
    "        string = 'and '.join(Text)\n",
    "        if self.previous_time == None:\n",
    "            self.previous_time = time.time()\n",
    "        new_time = time.time()\n",
    "        if 10<=new_time-self.previous_time<=20:\n",
    "            if speech=='pyttsx' and len(Text)>0:\n",
    "                engine.say(string)\n",
    "                engine.runAndWait()\n",
    "            elif speech=='gtts' and len(Text)>0:\n",
    "                filename = 'temp2.mp3'\n",
    "                tts = gTTS(text=string, lang='en-in')\n",
    "                tts.save(filename)\n",
    "                playsound(filename)\n",
    "        #sleep(music.duration) #prevent from killing\n",
    "                os.remove(filename) #remove temperory file\n",
    "            else : \n",
    "                print('no objects')\n",
    "            self.previous_time = new_time\n",
    "        else:\n",
    "            pass\n",
    "        return GRID,Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dist stereo\n",
    "class distStereo():\n",
    "    def __init__(self,thresh):\n",
    "        #self.dictl = dictleft\n",
    "        #self.dictr = dictright\n",
    "        self.thresh = thresh\n",
    "        self.previous_time = None\n",
    "    def ssd(self,yleft,yright):\n",
    "        return np.sum(np.square(yleft-yright))\n",
    "    def cal_s(self,dictleft,dictright):\n",
    "        #calculate the similarity between the pixels grid\n",
    "        #the grid dictionary of the left and right image will be using\n",
    "        \n",
    "        ###output\n",
    "        ## (left_pixel_value,right_pixel_value,object_name)= distance\n",
    "        new_dict = dict() \n",
    "        for keyl,valuel in dictleft.items():\n",
    "            #key consist (name,ctrx,ctry)\n",
    "            min_thresh = 100000\n",
    "            for keyr,valuer in dictright.items():\n",
    "                result= self.ssd(valuel,valuer)\n",
    "                print('left_image_name',keyl[0])\n",
    "                print('right_image_name',keyr[0])\n",
    "                print(\"Result\",result)\n",
    "                print(\"thresh\",self.thresh)\n",
    "                if result<self.thresh and keyl[0]==keyr[0]:\n",
    "                    #print(keyl[0])\n",
    "                    if result<min_thresh:\n",
    "                        min_thresh = result\n",
    "                        new_dict[(keyl[1],keyr[1],keyl[0])] = result\n",
    "                        \n",
    "        return new_dict\n",
    "    def distance(self,B,f,XL,XR,SIZE,dictleft,dictright,speech='pyttsx'):\n",
    "        #B is the distance between the camera in 'mm'\n",
    "        #XL is the  horizontal length of the plane for the left image plan in 'mm'\n",
    "        #XR is the horizontal length of the plane for the right image plan in 'mm'\n",
    "        #SIZE is the image dimension in pixel form #basically contain the number of column in pixels\n",
    "        #f is focal length\n",
    "        CS = self.cal_s(dictleft,dictright) #calculate similarity\n",
    "        #CS contains the (cooredinate_of object in left image,coordinate of object in the right image,name of the object)\n",
    "        dist = dict() #distance from the object\n",
    "        count = dict()\n",
    "        Text = []\n",
    "        approx_dist = 'near'\n",
    "        \n",
    "        for key,value in CS.items():\n",
    "            l = key[0]\n",
    "            xl = (XL/SIZE)*l-(XL/2) #pixel in mm\n",
    "            r = key[1]\n",
    "            xr = (XR/SIZE)*(r)-(XR/2) #pixel in mm\n",
    "            name = key[2]\n",
    "            try:\n",
    "                d = xl-xr #disparity\n",
    "                Distance =  int(B*f/d)\n",
    "                dist[(name,l,r,xl,xr)] = Distance\n",
    "                count[name] = count.get(name,0)+1\n",
    "                if Distance<100:\n",
    "                    approx_dist = ' near '\n",
    "                elif 100<Distance<300:\n",
    "                    approx_dist = ' little bit far ' \n",
    "                else:\n",
    "                    approx_dist = ' far '\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            Text.append(' '+name+' '+str(count[name])+' is' +approx_dist)\n",
    "            \n",
    "        string = 'and'.join(Text)\n",
    "        if self.previous_time == None:\n",
    "            self.previous_time = time.time()\n",
    "        new_time = time.time()\n",
    "        if 10<=new_time-self.previous_time<=20:\n",
    "            if speech=='pyttsx' and len(Text)>0:\n",
    "                engine.say(string)\n",
    "                engine.runAndWait()\n",
    "            elif speech=='gtts' and len(Text)>0:\n",
    "                filename = 'temp3.mp3'\n",
    "                tts = gTTS(text=string, lang='en-in')\n",
    "                tts.save(filename)\n",
    "                playsound(filename)\n",
    "        #sleep(music.duration) #prevent from killing\n",
    "                os.remove(filename) #remove temperory file\n",
    "            else : \n",
    "                print('no objects')\n",
    "            self.previous_time = new_time\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        return dist\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = face_recogntion()\n",
    "ob = object_detection()\n",
    "ds = distStereo(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check the right and left frames\n",
    "cap_left = cv2.VideoCapture(0)\n",
    "cap_right = cv2.VideoCapture(2)\n",
    "B =  7.4#cm\n",
    "f = .44 #cm\n",
    "FOV = 60 #degree\n",
    "XL = 2*f*math.tan(math.radians(FOV/2)) #Length the plane left camera\n",
    "XR = XL #length of plane is same as left camera\n",
    "SIZE = 640 #col lentgh in pixels\n",
    "video = True\n",
    "while True:\n",
    "    ret,framel = cap_left.read()\n",
    "    ret,framer = cap_right.read()\n",
    "    image_left = cv2.cvtColor(framel,cv2.COLOR_BGR2RGB)\n",
    "    image_right = cv2.cvtColor(framer,cv2.COLOR_BGR2RGB)\n",
    "    #faces,coord,faceimages = fc.face_detect(image,model_size=(160,160))\n",
    "    identify_face_left,face_image_left = fc.face_identification(image_left)\n",
    "    identify_face_right,face_image_right = fc.face_identification(image_right,T=0.7)\n",
    "    identify_face,face_image = fc.face_identification(image_left,T=0.7)\n",
    "    I_left,names_left = fc.display_face(identify_face_left,'left',face_image_left,speech = 'gtts')\n",
    "    I_right,names_right = fc.display_face(identify_face_right,'right',face_image_right,speech = 'gtts')\n",
    "\n",
    "    #grid_left,imagel = ob.take_object(I_left,'left',video=True,speech = 'no')\n",
    "    #grid_right,imager = ob.take_object(I_right,'right',video=True,speech = 'no')\n",
    "    #dist = ds.distance(B,f,XL,XR,SIZE,grid_left,grid_right)\n",
    "    #print(dist)\n",
    "    #SIZE = image.shape\n",
    "    cv2.imshow(\"face_left\",I_left)\n",
    "    cv2.imshow(\"face_right\",I_right)\n",
    "    cv2.imshow(\"Image\",framel)\n",
    "    #cv2.imshow(\"object_left\",imagel)\n",
    "    #cv2.imshow(\"object_right\",imager)\n",
    "    K = cv2.waitKey(5)\n",
    "    if K & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap_left.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
